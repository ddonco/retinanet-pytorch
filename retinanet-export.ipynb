{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import torch.cuda\n",
    "import torch.distributed\n",
    "import torch.multiprocessing\n",
    "\n",
    "from retinanet import infer, train, utils\n",
    "from retinanet.model import Model\n",
    "from retinanet import backbones\n",
    "from retinanet._C import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(config, verbose=False):\n",
    "    if config.command != 'train' and not os.path.isfile(config.model):\n",
    "        raise RuntimeError('Model file {} does not exist!'.format(config.model))\n",
    "\n",
    "    model = None\n",
    "    state = {}\n",
    "    _, ext = os.path.splitext(config.model)\n",
    "\n",
    "    if config.command == 'train' and (not os.path.exists(config.model) or config.override):\n",
    "        if verbose: print('Initializing model...')\n",
    "        model = Model(config.backbone, config.classes)\n",
    "        model.initialize(config.fine_tune)\n",
    "        if verbose: print(model)\n",
    "\n",
    "    elif ext == '.pth' or ext == '.torch':\n",
    "        if verbose: print('Loading model from {}...'.format(os.path.basename(config.model)))\n",
    "        model, state = Model.load(config.model)\n",
    "        if verbose: print(model)\n",
    "\n",
    "    elif config.command == 'infer' and ext in ['.engine', '.plan']:\n",
    "        model = None\n",
    "    \n",
    "    else:\n",
    "        raise RuntimeError('Invalid model format \"{}\"!'.format(config.ext))\n",
    "\n",
    "    state['path'] = config.model\n",
    "    return model, state\n",
    "\n",
    "def worker(rank, config, world, model, state):\n",
    "    'Per-device distributed worker'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        os.environ.update({\n",
    "            'MASTER_PORT': config.master.split(':')[-1],\n",
    "            'MASTER_ADDR': ':'.join(config.master.split(':')[:-1]),\n",
    "            'WORLD_SIZE':  str(world),\n",
    "            'RANK':        str(rank),\n",
    "            'CUDA_DEVICE': str(rank)\n",
    "        })\n",
    "\n",
    "        torch.cuda.set_device(rank)\n",
    "        if rank > 0:\n",
    "            torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "\n",
    "        if config.batch % world != 0:\n",
    "            raise RuntimeError('Batch size should be a multiple of the number of GPUs')\n",
    "\n",
    "    if config.command == 'train':\n",
    "        train.train(model, state, config.images, config.annotations,\n",
    "            config.val_images or config.images, config.val_annotations, config.resize, config.max_size, config.jitter, \n",
    "            config.batch, int(config.iters * config.schedule), config.val_iters, not config.full_precision, config.lr, \n",
    "            config.warmup, [int(m * config.schedule) for m in config.milestones], config.gamma, \n",
    "            is_master=(rank == 0), world=world, use_dali=config.with_dali,\n",
    "            metrics_url=config.post_metrics, logdir=config.logdir, verbose=(rank == 0))\n",
    "\n",
    "    elif config.command == 'infer':\n",
    "        if model is None:\n",
    "            if rank == 0: print('Loading CUDA engine from {}...'.format(os.path.basename(config.model)))\n",
    "            model = Engine.load(config.model)\n",
    "\n",
    "        infer.infer(model, config.images, config.output, config.resize, config.max_size, config.batch,\n",
    "            annotations=config.annotations, mixed_precision=not config.full_precision,\n",
    "            is_master=(rank == 0), world=world, use_dali=config.with_dali, verbose=(rank == 0))\n",
    "\n",
    "    elif config.command == 'export':\n",
    "        onnx_only = config.export.split('.')[-1] == 'onnx'\n",
    "        input_size = config.size * 2 if len(config.size) == 1 else config.size\n",
    "\n",
    "        calibration_files = []\n",
    "        if config.int8:\n",
    "            # Get list of images to use for calibration\n",
    "            if os.path.isdir(config.calibration_images):\n",
    "                import glob\n",
    "                file_extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "                for ex in file_extensions:\n",
    "                    calibration_files += glob.glob(\"{}/*{}\".format(config.calibration_images, ex), recursive=True)\n",
    "                # Only need enough images for specified num of calibration batches\n",
    "                if len(calibration_files) >= config.calibration_batches * config.batch:\n",
    "                    calibration_files = calibration_files[:(config.calibration_batches * config.batch)]\n",
    "                else:\n",
    "                    print('Only found enough images for {} batches. Continuing anyway...'.format(len(calibration_files) // config.batch))\n",
    "\n",
    "                random.shuffle(calibration_files)\n",
    "\n",
    "        precision = \"FP32\"\n",
    "        if config.int8:\n",
    "            precision = \"INT8\"\n",
    "        elif not config.full_precision:\n",
    "            precision = \"FP16\"\n",
    "\n",
    "        exported = model.export(input_size, config.batch, precision, calibration_files, config.calibration_table, config.verbose, onnx_only=onnx_only)\n",
    "        if onnx_only:\n",
    "            with open(config.export, 'wb') as out:\n",
    "                out.write(exported)\n",
    "        else:\n",
    "            exported.save(config.export)\n",
    "\n",
    "def main(config=None):\n",
    "    'Entry point for the retinanet command'\n",
    "\n",
    "    model, state = load_model(config, verbose=True)\n",
    "    if model: model.share_memory()\n",
    "\n",
    "    world = torch.cuda.device_count()\n",
    "    if config.command == 'export' or world <= 1:\n",
    "        worker(0, config, 1, model, state)\n",
    "    else:\n",
    "        torch.multiprocessing.spawn(worker, args=(config, world, model, state), nprocs=world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinanetConfig(object):\n",
    "    # Adress and port of the master worker\n",
    "    master = '127.0.0.1:29500'\n",
    "\n",
    "    # run mode: train, infer, export\n",
    "    command = 'train'\n",
    "\n",
    "    devcount = max(1, torch.cuda.device_count())\n",
    "\n",
    "    ### Train, Inference, and Export variables\n",
    "    # path to output model or checkpoint to resume from\n",
    "    model = 'models/retinanet_rn50fpn.pth'\n",
    "    # batch size, default for TensorRT engine is 2\n",
    "    batch = 2 * devcount\n",
    "    # train in full precision\n",
    "    full_precision = False\n",
    "    \n",
    "    ### Train and Inference variables\n",
    "    # path to COCO style annotations\n",
    "    annotations = 'labels/annotaions.json'\n",
    "    # path to images\n",
    "    images = 'images/'\n",
    "    # save detections to specified JSON file\n",
    "    output = 'detections.json'\n",
    "    # resize to given size\n",
    "    resize = 800\n",
    "    # maximum resizing size\n",
    "    max_size = 1333\n",
    "    # use dali for data loading\n",
    "    with_dali = False\n",
    "    \n",
    "    ### Train only variables\n",
    "    # path to COCO style validation annotations\n",
    "    val_annotations = 'labels/val-annotations.json'\n",
    "    # path to validation images\n",
    "    val_images = 'images/'\n",
    "    # backbone model (or list of)\n",
    "    backbone = ['ResNet50FPN']\n",
    "    # number of classes\n",
    "    classes = 80\n",
    "    # jitter size within range: [min, max]\n",
    "    jitter = [640, 1024]\n",
    "    # number of iterations to train for\n",
    "    iters = 90000\n",
    "    # list of iteration indices where learning rate decays\n",
    "    milestones = [60000, 80000]\n",
    "    # scale schedule (affecting iters and milestones)\n",
    "    schedule = 1\n",
    "    # learning rate\n",
    "    lr = 0.01\n",
    "    # numer of warmup iterations\n",
    "    warmup= 1000\n",
    "    # multiplicative factor of learning rate decay\n",
    "    gamma = 0.1\n",
    "    # override model\n",
    "    override = False\n",
    "    # post metrics to specified url\n",
    "    post_metrics = ''\n",
    "    # fine tune a pretrained model at provided path\n",
    "    fine_tune = ''\n",
    "    # directory where to write logs\n",
    "    logdir = 'logs/'\n",
    "    # number of iterations between each validation\n",
    "    val_iters = 8000\n",
    "\n",
    "    # Export only variables\n",
    "    # path to exported output\n",
    "    export = 'models/export.pth'\n",
    "    # input size (square) or sizes (h w) to use when generating TensorRT engine\n",
    "    size = [1280]\n",
    "    # calibrate model and export in int8 precision\n",
    "    int8 = False\n",
    "    # ONNX opset version (int)\n",
    "    opset = 10\n",
    "    # number of batches to use for int8 calibration\n",
    "    calibration_batches = 10\n",
    "    # path to calibration images to use for int8 calibration\n",
    "    calibration_images = \"\"\n",
    "    # path of existing calibration table to load from, or name of new calibration table\n",
    "    calibration_table = \"\"\n",
    "    # enable verbose logging\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetConfig(RetinanetConfig):\n",
    "    command = 'export'\n",
    "    model = '../models/retinanet_rn34fpn-finetune.pth'\n",
    "    export = '../models/retinanet_rn34fpn-finetune-export.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from retinanet_rn34fpn-finetune.pth...\n",
      "     model: RetinaNet\n",
      "  backbone: ResNet34FPN\n",
      "   classes: 1, anchors: 9\n",
      "Exporting to ONNX...\n"
     ]
    }
   ],
   "source": [
    "config = ResNetConfig()\n",
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
